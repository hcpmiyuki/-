{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 詳解ディープラーニング４章"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimuramiyuki/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多層パーセプトロンをPytorchで"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    '''\n",
    "    多層パーセプトロン\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.a1 = nn.Sigmoid()\n",
    "        self.l2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.a2 = nn.Sigmoid()\n",
    "        \n",
    "        self.layers = [self.l1, self.a1, self.l2, self.a2]\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # for文で順伝播を処理\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss:  8.6\n",
      "epoch: 1, loss:  8.49\n",
      "epoch: 2, loss:  8.43\n",
      "epoch: 3, loss:  8.37\n",
      "epoch: 4, loss:  8.31\n",
      "epoch: 5, loss:  8.25\n",
      "epoch: 6, loss:  8.2\n",
      "epoch: 7, loss:  8.15\n",
      "epoch: 8, loss:  8.09\n",
      "epoch: 9, loss:  8.03\n",
      "epoch: 10, loss:  7.97\n",
      "epoch: 11, loss:  7.9\n",
      "epoch: 12, loss:  7.83\n",
      "epoch: 13, loss:  7.75\n",
      "epoch: 14, loss:  7.67\n",
      "epoch: 15, loss:  7.59\n",
      "epoch: 16, loss:  7.5\n",
      "epoch: 17, loss:  7.4\n",
      "epoch: 18, loss:  7.31\n",
      "epoch: 19, loss:  7.21\n",
      "epoch: 20, loss:  7.11\n",
      "epoch: 21, loss:  7.0\n",
      "epoch: 22, loss:  6.89\n",
      "epoch: 23, loss:  6.79\n",
      "epoch: 24, loss:  6.69\n",
      "epoch: 25, loss:  6.59\n",
      "epoch: 26, loss:  6.49\n",
      "epoch: 27, loss:  6.38\n",
      "epoch: 28, loss:  6.29\n",
      "epoch: 29, loss:  6.21\n",
      "epoch: 30, loss:  6.12\n",
      "epoch: 31, loss:  6.03\n",
      "epoch: 32, loss:  5.95\n",
      "epoch: 33, loss:  5.88\n",
      "epoch: 34, loss:  5.81\n",
      "epoch: 35, loss:  5.74\n",
      "epoch: 36, loss:  5.69\n",
      "epoch: 37, loss:  5.64\n",
      "epoch: 38, loss:  5.57\n",
      "epoch: 39, loss:  5.53\n",
      "epoch: 40, loss:  5.48\n",
      "epoch: 41, loss:  5.44\n",
      "epoch: 42, loss:  5.4\n",
      "epoch: 43, loss:  5.36\n",
      "epoch: 44, loss:  5.33\n",
      "epoch: 45, loss:  5.29\n",
      "epoch: 46, loss:  5.26\n",
      "epoch: 47, loss:  5.23\n",
      "epoch: 48, loss:  5.21\n",
      "epoch: 49, loss:  5.18\n",
      "epoch: 50, loss:  5.17\n",
      "epoch: 51, loss:  5.13\n",
      "epoch: 52, loss:  5.12\n",
      "epoch: 53, loss:  5.09\n",
      "epoch: 54, loss:  5.07\n",
      "epoch: 55, loss:  5.06\n",
      "epoch: 56, loss:  5.04\n",
      "epoch: 57, loss:  5.03\n",
      "epoch: 58, loss:  5.01\n",
      "epoch: 59, loss:  4.99\n",
      "epoch: 60, loss:  4.98\n",
      "epoch: 61, loss:  4.96\n",
      "epoch: 62, loss:  4.96\n",
      "epoch: 63, loss:  4.94\n",
      "epoch: 64, loss:  4.93\n",
      "epoch: 65, loss:  4.92\n",
      "epoch: 66, loss:  4.91\n",
      "epoch: 67, loss:  4.91\n",
      "epoch: 68, loss:  4.89\n",
      "epoch: 69, loss:  4.88\n",
      "epoch: 70, loss:  4.88\n",
      "epoch: 71, loss:  4.86\n",
      "epoch: 72, loss:  4.85\n",
      "epoch: 73, loss:  4.84\n",
      "epoch: 74, loss:  4.84\n",
      "epoch: 75, loss:  4.84\n",
      "epoch: 76, loss:  4.83\n",
      "epoch: 77, loss:  4.82\n",
      "epoch: 78, loss:  4.82\n",
      "epoch: 79, loss:  4.82\n",
      "epoch: 80, loss:  4.81\n",
      "epoch: 81, loss:  4.81\n",
      "epoch: 82, loss:  4.8\n",
      "epoch: 83, loss:  4.79\n",
      "epoch: 84, loss:  4.78\n",
      "epoch: 85, loss:  4.78\n",
      "epoch: 86, loss:  4.78\n",
      "epoch: 87, loss:  4.77\n",
      "epoch: 88, loss:  4.77\n",
      "epoch: 89, loss:  4.78\n",
      "epoch: 90, loss:  4.76\n",
      "epoch: 91, loss:  4.76\n",
      "epoch: 92, loss:  4.76\n",
      "epoch: 93, loss:  4.76\n",
      "epoch: 94, loss:  4.75\n",
      "epoch: 95, loss:  4.75\n",
      "epoch: 96, loss:  4.75\n",
      "epoch: 97, loss:  4.74\n",
      "epoch: 98, loss:  4.75\n",
      "epoch: 99, loss:  4.74\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    np.random.seed(123)\n",
    "    torch.manual_seed(123)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # cpuとgpuのどちらを使用するか自動切り替え\n",
    "    \n",
    "    '''\n",
    "    1. データ準備\n",
    "    '''\n",
    "    N = 300\n",
    "    x, t = datasets.make_moons(N, noise=0.3)\n",
    "    t = t.reshape(N, 1)\n",
    "    \n",
    "    x_train, x_test, t_train, t_test = train_test_split(x, t, test_size=0.2)\n",
    "    '''\n",
    "    2.モデルの構築\n",
    "    '''\n",
    "    model = MLP(2, 3, 1).to(device)\n",
    "    \n",
    "    '''\n",
    "    3.モデルの学習\n",
    "    '''\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optimizers.SGD(model.parameters(), lr=0.1)\n",
    "    \n",
    "    def compute_loss(t, y):\n",
    "        return criterion(y, t)\n",
    "    \n",
    "    def train_step(x, t):\n",
    "        model.train()\n",
    "        preds = model(x)\n",
    "        loss = compute_loss(t, preds)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        return loss\n",
    "    \n",
    "    epochs = 100\n",
    "    batch_size = 20\n",
    "    n_batches = x_train.shape[0] // batch_size # 何回文あるか\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_loss = 0.\n",
    "        x_, t_ = shuffle(x_train, t_train)\n",
    "        # pytorchのテンソルに変換\n",
    "        x_ = torch.Tensor(x_).to(device)\n",
    "        t_ = torch.Tensor(t_).to(device)\n",
    "        \n",
    "        for n_batch in range(n_batches):\n",
    "            start = n_batch*batch_size # 窓をずらしていく感じ\n",
    "            end = start + batch_size\n",
    "            loss = train_step(x_[start:end], t_[start:end])\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        print(\"epoch: {}, loss: {: .3}\".format(epoch, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss:  0.318, test_acc:  0.867\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "4.モデルの評価\n",
    "'''\n",
    "\n",
    "def test_step(x, t):\n",
    "    # pytorchのテンソルに変換\n",
    "    x = torch.Tensor(x).to(device)\n",
    "    t = torch.Tensor(t).to(device)\n",
    "    model.eval()\n",
    "    preds = model(x)\n",
    "    loss = compute_loss(t, preds)\n",
    "    return loss, preds\n",
    "\n",
    "loss, preds = test_step(x_test, t_test)\n",
    "test_loss = loss.item()\n",
    "preds = preds.data.cpu().numpy() > 0.5\n",
    "test_acc = accuracy_score(t_test, preds)\n",
    "\n",
    "print(\"test_loss: {: .3}, test_acc: {: .3}\".format(\n",
    "    test_loss, test_acc\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 画像データの扱い方"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "root = os.path.join('~', '.torch', 'mnist')\n",
    "\n",
    "# tensor型に変換, （28, 28）次元から (784, )に変換\n",
    "transform = transforms.Compose([transforms.ToTensor(), lambda x: x.view(-1)]) #view()はnumpyのshape()と同じ\n",
    "mnist_train = datasets.MNIST(root=root, download=True, train=True, transform=transform)\n",
    "# DataLoaderオブジェクトに変換する\n",
    "train_dataloader = DataLoader(mnist_train, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.b1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.a1 = nn.ReLU()\n",
    "        self.d1 = nn.Dropout(0.5)\n",
    "        self.l2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.b2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.a2 = nn.ReLU()\n",
    "        self.d2 = nn.Dropout(0.5)\n",
    "        self.l3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.b3 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.a3 = nn.ReLU()\n",
    "        self.d3 = nn.Dropout(0.5)\n",
    "        self.l4 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        self.layers = [self.l1, self.b1, self.a1, self.d1, self.l2, self.b2, self.a2, self.d2, self.l3, self.b3, self.a3, self.d3, self.l4]\n",
    "        \n",
    "        # 重みの初期化\n",
    "        for layer in self.layers:\n",
    "            if type(layer) == nn.Linear:\n",
    "                nn.init.kaiming_normal_(layer.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss: 1.26, acc: 0.574, val_loss: 0.374, val_acc:  0.894\n",
      "epoch:2, loss: 0.446, acc: 0.869, val_loss: 0.239, val_acc:  0.929\n",
      "epoch:3, loss: 0.327, acc: 0.905, val_loss: 0.185, val_acc:  0.945\n",
      "epoch:4, loss: 0.268, acc: 0.923, val_loss: 0.161, val_acc:  0.954\n",
      "epoch:5, loss: 0.24, acc: 0.932, val_loss: 0.145, val_acc:  0.96\n",
      "epoch:6, loss: 0.209, acc: 0.94, val_loss: 0.139, val_acc:  0.961\n",
      "epoch:7, loss: 0.198, acc: 0.943, val_loss: 0.122, val_acc:  0.966\n",
      "epoch:8, loss: 0.185, acc: 0.946, val_loss: 0.123, val_acc:  0.966\n",
      "epoch:9, loss: 0.175, acc: 0.95, val_loss: 0.122, val_acc:  0.964\n",
      "epoch:10, loss: 0.163, acc: 0.953, val_loss: 0.114, val_acc:  0.969\n",
      "epoch:11, loss: 0.157, acc: 0.955, val_loss: 0.111, val_acc:  0.969\n",
      "epoch:12, loss: 0.148, acc: 0.957, val_loss: 0.108, val_acc:  0.97\n",
      "epoch:13, loss: 0.147, acc: 0.958, val_loss: 0.111, val_acc:  0.971\n",
      "epoch:14, loss: 0.138, acc: 0.96, val_loss: 0.106, val_acc:  0.971\n",
      "epoch:15, loss: 0.134, acc: 0.961, val_loss: 0.104, val_acc:  0.97\n",
      "epoch:16, loss: 0.127, acc: 0.963, val_loss: 0.104, val_acc:  0.972\n",
      "epoch:17, loss: 0.13, acc: 0.962, val_loss: 0.102, val_acc:  0.972\n",
      "epoch:18, loss: 0.125, acc: 0.963, val_loss: 0.0987, val_acc:  0.973\n",
      "epoch:19, loss: 0.12, acc: 0.965, val_loss: 0.0997, val_acc:  0.974\n",
      "epoch:20, loss: 0.115, acc: 0.966, val_loss: 0.101, val_acc:  0.971\n",
      "epoch:21, loss: 0.115, acc: 0.967, val_loss: 0.0936, val_acc:  0.974\n",
      "epoch:22, loss: 0.111, acc: 0.967, val_loss: 0.0958, val_acc:  0.974\n",
      "epoch:23, loss: 0.108, acc: 0.968, val_loss: 0.0944, val_acc:  0.975\n",
      "epoch:24, loss: 0.111, acc: 0.968, val_loss: 0.096, val_acc:  0.975\n",
      "epoch:25, loss: 0.107, acc: 0.969, val_loss: 0.0953, val_acc:  0.974\n",
      "epoch:26, loss: 0.1, acc: 0.97, val_loss: 0.0968, val_acc:  0.973\n",
      "epoch:27, loss: 0.0958, acc: 0.972, val_loss: 0.0955, val_acc:  0.975\n",
      "epoch:28, loss: 0.0998, acc: 0.97, val_loss: 0.095, val_acc:  0.975\n",
      "epoch:29, loss: 0.0957, acc: 0.972, val_loss: 0.0931, val_acc:  0.976\n",
      "epoch:30, loss: 0.0958, acc: 0.971, val_loss: 0.0951, val_acc:  0.976\n",
      "epoch:31, loss: 0.0923, acc: 0.973, val_loss: 0.0932, val_acc:  0.976\n",
      "epoch:32, loss: 0.088, acc: 0.974, val_loss: 0.0962, val_acc:  0.976\n",
      "epoch:33, loss: 0.0886, acc: 0.974, val_loss: 0.0937, val_acc:  0.975\n",
      "epoch:34, loss: 0.0881, acc: 0.974, val_loss: 0.0909, val_acc:  0.977\n",
      "epoch:35, loss: 0.0859, acc: 0.974, val_loss: 0.092, val_acc:  0.976\n",
      "epoch:36, loss: 0.0865, acc: 0.974, val_loss: 0.0917, val_acc:  0.976\n",
      "epoch:37, loss: 0.0796, acc: 0.976, val_loss: 0.0915, val_acc:  0.977\n",
      "epoch:38, loss: 0.0842, acc: 0.974, val_loss: 0.0909, val_acc:  0.977\n",
      "epoch:39, loss: 0.0827, acc: 0.975, val_loss: 0.0928, val_acc:  0.977\n",
      "epoch:40, loss: 0.0807, acc: 0.976, val_loss: 0.0933, val_acc:  0.977\n",
      "epoch:41, loss: 0.0782, acc: 0.976, val_loss: 0.0882, val_acc:  0.979\n",
      "epoch:42, loss: 0.0772, acc: 0.976, val_loss: 0.0887, val_acc:  0.977\n",
      "epoch:43, loss: 0.0789, acc: 0.976, val_loss: 0.0915, val_acc:  0.978\n",
      "epoch:44, loss: 0.0782, acc: 0.976, val_loss: 0.0888, val_acc:  0.977\n",
      "epoch:45, loss: 0.0743, acc: 0.978, val_loss: 0.091, val_acc:  0.977\n",
      "epoch:46, loss: 0.0733, acc: 0.978, val_loss: 0.0929, val_acc:  0.976\n",
      "epoch:47, loss: 0.0754, acc: 0.977, val_loss: 0.0927, val_acc:  0.977\n",
      "epoch:48, loss: 0.0733, acc: 0.978, val_loss: 0.0933, val_acc:  0.977\n",
      "epoch:49, loss: 0.0746, acc: 0.977, val_loss: 0.0948, val_acc:  0.975\n",
      "epoch:50, loss: 0.0704, acc: 0.978, val_loss: 0.0921, val_acc:  0.976\n",
      "epoch:51, loss: 0.072, acc: 0.979, val_loss: 0.0964, val_acc:  0.975\n",
      "epoch:52, loss: 0.0708, acc: 0.979, val_loss: 0.0935, val_acc:  0.978\n",
      "epoch:53, loss: 0.0695, acc: 0.979, val_loss: 0.0958, val_acc:  0.977\n",
      "epoch:54, loss: 0.067, acc: 0.98, val_loss: 0.0933, val_acc:  0.978\n",
      "epoch:55, loss: 0.0699, acc: 0.978, val_loss: 0.093, val_acc:  0.977\n",
      "epoch:56, loss: 0.0653, acc: 0.98, val_loss: 0.0943, val_acc:  0.977\n",
      "epoch:57, loss: 0.0683, acc: 0.979, val_loss: 0.0914, val_acc:  0.977\n",
      "epoch:58, loss: 0.0693, acc: 0.979, val_loss: 0.0964, val_acc:  0.976\n",
      "epoch:59, loss: 0.0694, acc: 0.979, val_loss: 0.0925, val_acc:  0.977\n",
      "epoch:60, loss: 0.0636, acc: 0.98, val_loss: 0.091, val_acc:  0.978\n",
      "epoch:61, loss: 0.0654, acc: 0.98, val_loss: 0.0944, val_acc:  0.978\n",
      "epoch:62, loss: 0.0657, acc: 0.98, val_loss: 0.093, val_acc:  0.978\n",
      "epoch:63, loss: 0.0647, acc: 0.98, val_loss: 0.0965, val_acc:  0.976\n",
      "epoch:64, loss: 0.0649, acc: 0.98, val_loss: 0.0986, val_acc:  0.976\n",
      "epoch:65, loss: 0.0615, acc: 0.981, val_loss: 0.0907, val_acc:  0.978\n",
      "epoch:66, loss: 0.0598, acc: 0.982, val_loss: 0.0926, val_acc:  0.978\n",
      "epoch:67, loss: 0.0627, acc: 0.982, val_loss: 0.0924, val_acc:  0.978\n",
      "epoch:68, loss: 0.0595, acc: 0.982, val_loss: 0.0927, val_acc:  0.978\n",
      "epoch:69, loss: 0.0597, acc: 0.981, val_loss: 0.0974, val_acc:  0.977\n",
      "epoch:70, loss: 0.0626, acc: 0.981, val_loss: 0.0961, val_acc:  0.976\n",
      "epoch:71, loss: 0.0613, acc: 0.982, val_loss: 0.0954, val_acc:  0.977\n",
      "epoch:72, loss: 0.062, acc: 0.982, val_loss: 0.0979, val_acc:  0.976\n",
      "epoch:73, loss: 0.0582, acc: 0.982, val_loss: 0.0996, val_acc:  0.977\n",
      "epoch:74, loss: 0.0581, acc: 0.982, val_loss: 0.0917, val_acc:  0.978\n",
      "epoch:75, loss: 0.0564, acc: 0.982, val_loss: 0.0942, val_acc:  0.979\n",
      "epoch:76, loss: 0.056, acc: 0.984, val_loss: 0.0967, val_acc:  0.979\n",
      "epoch:77, loss: 0.057, acc: 0.982, val_loss: 0.0945, val_acc:  0.978\n",
      "epoch:78, loss: 0.0555, acc: 0.983, val_loss: 0.0949, val_acc:  0.978\n",
      "epoch:79, loss: 0.0567, acc: 0.983, val_loss: 0.0983, val_acc:  0.977\n",
      "epoch:80, loss: 0.0568, acc: 0.982, val_loss: 0.0943, val_acc:  0.979\n",
      "epoch:81, loss: 0.055, acc: 0.983, val_loss: 0.0967, val_acc:  0.978\n",
      "epoch:82, loss: 0.0545, acc: 0.984, val_loss: 0.0961, val_acc:  0.978\n",
      "epoch:83, loss: 0.0562, acc: 0.983, val_loss: 0.0955, val_acc:  0.978\n",
      "epoch:84, loss: 0.0527, acc: 0.984, val_loss: 0.0949, val_acc:  0.977\n",
      "epoch:85, loss: 0.0524, acc: 0.983, val_loss: 0.097, val_acc:  0.978\n",
      "epoch:86, loss: 0.0522, acc: 0.984, val_loss: 0.097, val_acc:  0.979\n",
      "epoch:87, loss: 0.0553, acc: 0.984, val_loss: 0.0924, val_acc:  0.979\n",
      "epoch:88, loss: 0.0502, acc: 0.985, val_loss: 0.0942, val_acc:  0.979\n",
      "epoch:89, loss: 0.053, acc: 0.984, val_loss: 0.0982, val_acc:  0.978\n",
      "epoch:90, loss: 0.052, acc: 0.984, val_loss: 0.0967, val_acc:  0.978\n",
      "epoch:91, loss: 0.0485, acc: 0.985, val_loss: 0.0948, val_acc:  0.978\n",
      "epoch:92, loss: 0.0503, acc: 0.984, val_loss: 0.0976, val_acc:  0.979\n",
      "epoch:93, loss: 0.0508, acc: 0.985, val_loss: 0.0978, val_acc:  0.978\n",
      "epoch:94, loss: 0.0489, acc: 0.985, val_loss: 0.0982, val_acc:  0.978\n",
      "epoch:95, loss: 0.0517, acc: 0.984, val_loss: 0.0957, val_acc:  0.978\n",
      "epoch:96, loss: 0.0507, acc: 0.984, val_loss: 0.0954, val_acc:  0.979\n",
      "epoch:97, loss: 0.0515, acc: 0.984, val_loss: 0.0966, val_acc:  0.978\n",
      "epoch:98, loss: 0.0493, acc: 0.985, val_loss: 0.0973, val_acc:  0.978\n",
      "epoch:99, loss: 0.0497, acc: 0.984, val_loss: 0.0979, val_acc:  0.979\n",
      "epoch:100, loss: 0.0502, acc: 0.984, val_loss: 0.0966, val_acc:  0.978\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "# tensor型に変換, （28, 28）次元から (784, )に変換\n",
    "transform = transforms.Compose([transforms.ToTensor(), lambda x: x.view(-1)]) #view()はnumpyのshape()と同じ\n",
    "mnist_train = datasets.MNIST(root=root, download=True, train=True, transform=transform)\n",
    "mnist_test = datasets.MNIST(root=root, download=True, train=False, transform=transform)\n",
    "\n",
    "n_samples = len(mnist_train)\n",
    "n_train = int(n_samples * 0.8)\n",
    "n_val = n_samples - n_train\n",
    "\n",
    "mnist_train, mnist_val = random_split(mnist_train, [n_train, n_val]) \n",
    "# DataLoaderオブジェクトに変換する\n",
    "train_dataloader = DataLoader(mnist_train, batch_size=100, shuffle=True)\n",
    "test_dataloader = DataLoader(mnist_test, batch_size=100, shuffle=False)\n",
    "val_dataloader = DataLoader(mnist_val, batch_size=100, shuffle=False)\n",
    "\n",
    "model = DNN(784, 200, 10).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optimizers.SGD(model.parameters(), lr=0.1)\n",
    "    \n",
    "def compute_loss(t, y):\n",
    "    return criterion(y, t)\n",
    "\n",
    "def train_step(x, t):\n",
    "    model.train()\n",
    "    preds = model(x)\n",
    "    loss = compute_loss(t, preds)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss, preds\n",
    "\n",
    "def val_step(x, t):\n",
    "    model.eval()\n",
    "    preds = model(x)\n",
    "    loss = compute_loss(t, preds)\n",
    "    return loss, preds\n",
    "\n",
    "\n",
    "epochs = 100\n",
    "hist = {\"val_loss\": [], \"val_accuracy\": []}\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.\n",
    "    train_acc = 0.\n",
    "    val_loss = 0.\n",
    "    val_acc = 0.\n",
    "    \n",
    "    for (x, t) in train_dataloader:\n",
    "        x, t = x.to(device), t.to(device)\n",
    "        loss, preds = train_step(x, t)\n",
    "        train_loss += loss.item()\n",
    "        train_acc += accuracy_score(t.tolist(), preds.argmax(dim = -1).tolist())\n",
    "    \n",
    "    train_loss /= len(train_dataloader)\n",
    "    train_acc /= len(train_dataloader)\n",
    "    \n",
    "    for (x, t) in val_dataloader:\n",
    "        x, t = x.to(device), t.to(device)\n",
    "        loss, preds = val_step(x, t)\n",
    "        val_loss += loss.item()\n",
    "        val_acc += accuracy_score(t.tolist(), preds.argmax(dim = -1).tolist())\n",
    "    \n",
    "    val_loss /= len(val_dataloader)\n",
    "    val_acc /= len(val_dataloader)\n",
    "    hist[\"val_loss\"].append(val_loss)\n",
    "    hist[\"val_accuracy\"].append(val_acc)\n",
    "    print(\"epoch:{}, loss:{: .3}, acc:{: .3}, val_loss:{: .3}, val_acc: {: .3}\".format(\n",
    "        epoch+1,\n",
    "        train_loss,\n",
    "        train_acc,\n",
    "        val_loss, \n",
    "        val_acc\n",
    "    ))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "val_loss = hist[\"val_loss\"]\n",
    "val_acc = hist[\"val_accuracy\"]\n",
    " \n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(range(len(val_loss)), val_loss, color=\"b\", linewidth=1)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    " \n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(range(len(val_acc)), val_acc, color=\"b\", linewidth=1)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"acc\")\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 勾配消失防ぐ\n",
    "    + 活性化関数を工夫（tanh, ReLU, Swish等）\n",
    "+ オーバーフィッティング防ぐ\n",
    "    + ドロップアウトを導入して、ニューロンをランダムに除外させなが学習する。そうすることで、擬似的に複数のモデルで学習していることになる(=アンサンブル学習)\n",
    "    + ドロップアウトを導入する場合は重みの最適化に時間がかかるため、エポック数を増やす必要がある\n",
    "+ 評価誤差が何エポックか連続で減ったら早期終了させると良い\n",
    "+ バッチ正規化はミニバッチごとの平均・分散を計算することで学習の安定化を測る手法なので、バッチサイズを極端に小さくすると学習が不安定になりやすくなる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping():\n",
    "    def __init__(self, patience=0, verbose=0):\n",
    "        self._count = 0\n",
    "        self._loss = float(\"inf\")\n",
    "        self.verbose = verbose\n",
    "        self.patience = patience\n",
    "        \n",
    "    def __call__(self, loss):\n",
    "        if self._loss < loss:\n",
    "            self._count += 1\n",
    "            if self._count >= self.patience:\n",
    "                if self.verbose:\n",
    "                    print(\"early stopping\")\n",
    "                    return True\n",
    "        else:\n",
    "            self._count = 0\n",
    "            self._loss = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss: 0.805, acc: 0.745, val_loss: 0.232, val_acc:  0.929\n",
      "epoch:2, loss: 0.393, acc: 0.884, val_loss: 0.173, val_acc:  0.948\n",
      "epoch:3, loss: 0.314, acc: 0.907, val_loss: 0.143, val_acc:  0.955\n",
      "epoch:4, loss: 0.275, acc: 0.918, val_loss: 0.126, val_acc:  0.96\n",
      "epoch:5, loss: 0.244, acc: 0.928, val_loss: 0.112, val_acc:  0.967\n",
      "epoch:6, loss: 0.218, acc: 0.935, val_loss: 0.104, val_acc:  0.968\n",
      "epoch:7, loss: 0.2, acc: 0.94, val_loss: 0.102, val_acc:  0.968\n",
      "epoch:8, loss: 0.189, acc: 0.945, val_loss: 0.0935, val_acc:  0.972\n",
      "epoch:9, loss: 0.178, acc: 0.947, val_loss: 0.0883, val_acc:  0.975\n",
      "epoch:10, loss: 0.163, acc: 0.951, val_loss: 0.0875, val_acc:  0.975\n",
      "epoch:11, loss: 0.156, acc: 0.954, val_loss: 0.0835, val_acc:  0.976\n",
      "epoch:12, loss: 0.152, acc: 0.955, val_loss: 0.0815, val_acc:  0.976\n",
      "epoch:13, loss: 0.147, acc: 0.956, val_loss: 0.0808, val_acc:  0.977\n",
      "epoch:14, loss: 0.144, acc: 0.957, val_loss: 0.0792, val_acc:  0.977\n",
      "epoch:15, loss: 0.136, acc: 0.958, val_loss: 0.076, val_acc:  0.978\n",
      "epoch:16, loss: 0.135, acc: 0.959, val_loss: 0.0727, val_acc:  0.978\n",
      "epoch:17, loss: 0.129, acc: 0.962, val_loss: 0.0715, val_acc:  0.978\n",
      "epoch:18, loss: 0.12, acc: 0.964, val_loss: 0.0698, val_acc:  0.98\n",
      "epoch:19, loss: 0.12, acc: 0.964, val_loss: 0.0692, val_acc:  0.979\n",
      "epoch:20, loss: 0.116, acc: 0.964, val_loss: 0.0743, val_acc:  0.979\n",
      "epoch:21, loss: 0.118, acc: 0.965, val_loss: 0.0705, val_acc:  0.979\n",
      "epoch:22, loss: 0.114, acc: 0.966, val_loss: 0.0714, val_acc:  0.98\n",
      "epoch:23, loss: 0.112, acc: 0.966, val_loss: 0.0694, val_acc:  0.98\n",
      "epoch:24, loss: 0.104, acc: 0.969, val_loss: 0.0682, val_acc:  0.981\n",
      "epoch:25, loss: 0.102, acc: 0.969, val_loss: 0.0674, val_acc:  0.981\n",
      "epoch:26, loss: 0.0986, acc: 0.97, val_loss: 0.0677, val_acc:  0.98\n",
      "epoch:27, loss: 0.103, acc: 0.97, val_loss: 0.0665, val_acc:  0.982\n",
      "epoch:28, loss: 0.0993, acc: 0.969, val_loss: 0.0679, val_acc:  0.981\n",
      "epoch:29, loss: 0.0926, acc: 0.971, val_loss: 0.0643, val_acc:  0.982\n",
      "epoch:30, loss: 0.0956, acc: 0.971, val_loss: 0.0648, val_acc:  0.981\n",
      "epoch:31, loss: 0.0926, acc: 0.971, val_loss: 0.0653, val_acc:  0.981\n",
      "epoch:32, loss: 0.0923, acc: 0.972, val_loss: 0.0649, val_acc:  0.981\n",
      "epoch:33, loss: 0.0896, acc: 0.972, val_loss: 0.0624, val_acc:  0.981\n",
      "epoch:34, loss: 0.0894, acc: 0.972, val_loss: 0.0613, val_acc:  0.983\n",
      "epoch:35, loss: 0.0893, acc: 0.972, val_loss: 0.0625, val_acc:  0.983\n",
      "epoch:36, loss: 0.0859, acc: 0.973, val_loss: 0.0603, val_acc:  0.983\n",
      "epoch:37, loss: 0.0825, acc: 0.975, val_loss: 0.0602, val_acc:  0.983\n",
      "epoch:38, loss: 0.0852, acc: 0.974, val_loss: 0.0616, val_acc:  0.983\n",
      "epoch:39, loss: 0.0833, acc: 0.974, val_loss: 0.0643, val_acc:  0.981\n",
      "epoch:40, loss: 0.0809, acc: 0.975, val_loss: 0.0636, val_acc:  0.982\n",
      "epoch:41, loss: 0.082, acc: 0.975, val_loss: 0.0632, val_acc:  0.982\n",
      "epoch:42, loss: 0.0821, acc: 0.974, val_loss: 0.0591, val_acc:  0.983\n",
      "epoch:43, loss: 0.0778, acc: 0.976, val_loss: 0.0634, val_acc:  0.982\n",
      "epoch:44, loss: 0.0746, acc: 0.977, val_loss: 0.0628, val_acc:  0.983\n",
      "epoch:45, loss: 0.0779, acc: 0.976, val_loss: 0.0605, val_acc:  0.983\n",
      "epoch:46, loss: 0.0738, acc: 0.976, val_loss: 0.0622, val_acc:  0.983\n",
      "epoch:47, loss: 0.0752, acc: 0.976, val_loss: 0.063, val_acc:  0.983\n",
      "early stopping\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "# tensor型に変換, （28, 28）次元から (784, )に変換\n",
    "transform = transforms.Compose([transforms.ToTensor(), lambda x: x.view(-1)]) #view()はnumpyのshape()と同じ\n",
    "mnist_train = datasets.MNIST(root=root, download=True, train=True, transform=transform)\n",
    "mnist_test = datasets.MNIST(root=root, download=True, train=False, transform=transform)\n",
    "\n",
    "n_samples = len(mnist_train)\n",
    "n_train = int(n_samples * 0.8)\n",
    "n_val = n_samples - n_train\n",
    "\n",
    "mnist_train, mnist_val = random_split(mnist_train, [n_train, n_val]) \n",
    "# DataLoaderオブジェクトに変換する\n",
    "train_dataloader = DataLoader(mnist_train, batch_size=100, shuffle=True)\n",
    "test_dataloader = DataLoader(mnist_test, batch_size=100, shuffle=False)\n",
    "val_dataloader = DataLoader(mnist_val, batch_size=100, shuffle=False)\n",
    "\n",
    "model = DNN(784, 200, 10).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optimizers.Adam(\n",
    "                            model.parameters(), \n",
    "                            lr=0.001,\n",
    "                            betas=(0.9, 0.999),\n",
    "                            amsgrad=True\n",
    "                           )\n",
    "    \n",
    "def compute_loss(t, y):\n",
    "    return criterion(y, t)\n",
    "\n",
    "def train_step(x, t):\n",
    "    model.train()\n",
    "    preds = model(x)\n",
    "    loss = compute_loss(t, preds)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss, preds\n",
    "\n",
    "def val_step(x, t):\n",
    "    model.eval()\n",
    "    preds = model(x)\n",
    "    loss = compute_loss(t, preds)\n",
    "    return loss, preds\n",
    "\n",
    "\n",
    "epochs = 100\n",
    "hist = {\"val_loss\": [], \"val_accuracy\": []}\n",
    "es = EarlyStopping(5, 1)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.\n",
    "    train_acc = 0.\n",
    "    val_loss = 0.\n",
    "    val_acc = 0.\n",
    "    \n",
    "    for (x, t) in train_dataloader:\n",
    "        x, t = x.to(device), t.to(device)\n",
    "        loss, preds = train_step(x, t)\n",
    "        train_loss += loss.item()\n",
    "        train_acc += accuracy_score(t.tolist(), preds.argmax(dim = -1).tolist())\n",
    "    \n",
    "    train_loss /= len(train_dataloader)\n",
    "    train_acc /= len(train_dataloader)\n",
    "    \n",
    "    for (x, t) in val_dataloader:\n",
    "        x, t = x.to(device), t.to(device)\n",
    "        loss, preds = val_step(x, t)\n",
    "        val_loss += loss.item()\n",
    "        val_acc += accuracy_score(t.tolist(), preds.argmax(dim = -1).tolist())\n",
    "    \n",
    "    val_loss /= len(val_dataloader)\n",
    "    val_acc /= len(val_dataloader)\n",
    "    hist[\"val_loss\"].append(val_loss)\n",
    "    hist[\"val_accuracy\"].append(val_acc)\n",
    "    print(\"epoch:{}, loss:{: .3}, acc:{: .3}, val_loss:{: .3}, val_acc: {: .3}\".format(\n",
    "        epoch+1,\n",
    "        train_loss,\n",
    "        train_acc,\n",
    "        val_loss, \n",
    "        val_acc\n",
    "    ))\n",
    "    \n",
    "    if es(val_loss):\n",
    "        break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "val_loss = hist[\"val_loss\"]\n",
    "val_acc = hist[\"val_accuracy\"]\n",
    " \n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(range(len(val_loss)), val_loss, color=\"b\", linewidth=1)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    " \n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(range(len(val_acc)), val_acc, color=\"b\", linewidth=1)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"acc\")\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
